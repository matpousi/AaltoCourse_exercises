{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: line_profiler in /opt/homebrew/anaconda3/lib/python3.12/site-packages (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "# install line profiler\n",
    "!pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magics: ensures that any changes to the modules loaded below will be re-loaded automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "\n",
    "# load general packages\n",
    "import numpy as np\n",
    "\n",
    "# load modules related to this exercise\n",
    "from model_zucher import zurcher\n",
    "from Solve_NFXP import solve_NFXP\n",
    "import estimate_NFXP as estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Look at ReadMe.txt to get an overview of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Invistigate how the code works, that is ensure you understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.init</li>\n",
    "<li> zurcher.setup</li>\n",
    "<li> zurcher.create_grid</li>\n",
    "<li> zucher.state_transition </li>\n",
    "<li> zucher.bellman </li>\n",
    "\n",
    "You can see how they are called below\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fill in the missing stuff in the function zucher.bellman and run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model grid:\n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Transition probabilities conditional on not replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.15]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.35]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "Transition probabilities conditional on replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "Bellman one run:\n",
      " [0.47323702 0.47170994 0.47018428 0.46866004 0.46713722 0.46561582\n",
      " 0.46409584 0.46257729 0.46106015 0.45962006 0.45833254 0.45734867]\n"
     ]
    }
   ],
   "source": [
    "do_settings = {\n",
    "    'RC': 0.5,\n",
    "    'n': 12,\n",
    "    'p':[0.65,0.2,0.1]   \n",
    "}\n",
    "model = zurcher(**do_settings)\n",
    "\n",
    "print('Model grid:\\n',model.grid)\n",
    "print('Transition probabilities conditional on not replacing:\\n',model.P1)\n",
    "print('Transition probabilities conditional on replacing:\\n',model.P2)\n",
    "ev,pk, dev = model.bellman(np.zeros((model.n)),output=3)\n",
    "print('Bellman one run:\\n',ev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "### 4. Solve the model. In order to solve the model, you should understand:\n",
    "<li> solve_NFXP.init</li>\n",
    "<li> solve_NFXP.setup</li>\n",
    "<li> solve_NFXP.poly </li>\n",
    "<li> solve_NFXP.sa </li>\n",
    "<li> solve_NFXP.nk </li>\n",
    "</il>\n",
    "You can see how they are called below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin contraction iterations (for the 1 time)\n",
      "Iteration 1, tol     0.4273, tol(j)/tol(j-1)          1\n",
      "Iteration 2, tol     0.4272, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 3, tol     0.4272, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 4, tol     0.4271, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 5, tol     0.4271, tol(j)/tol(j-1)     0.9998\n",
      "Iteration 6, tol      0.427, tol(j)/tol(j-1)     0.9998\n",
      "Iteration 7, tol     0.4269, tol(j)/tol(j-1)     0.9998\n",
      "Iteration 8, tol     0.4268, tol(j)/tol(j-1)     0.9997\n",
      "Iteration 9, tol     0.4266, tol(j)/tol(j-1)     0.9996\n",
      "Iteration 10, tol     0.4264, tol(j)/tol(j-1)     0.9995\n",
      "Iteration 11, tol     0.4261, tol(j)/tol(j-1)     0.9994\n",
      "Iteration 12, tol     0.4258, tol(j)/tol(j-1)     0.9991\n",
      "Iteration 13, tol     0.4253, tol(j)/tol(j-1)     0.9988\n",
      "Iteration 14, tol     0.4246, tol(j)/tol(j-1)     0.9984\n",
      "Iteration 15, tol     0.4237, tol(j)/tol(j-1)     0.9978\n",
      "Iteration 16, tol     0.4224, tol(j)/tol(j-1)      0.997\n",
      "Iteration 17, tol     0.4207, tol(j)/tol(j-1)      0.996\n",
      "Iteration 18, tol     0.4185, tol(j)/tol(j-1)     0.9947\n",
      "Iteration 19, tol     0.4156, tol(j)/tol(j-1)      0.993\n",
      "Iteration 20, tol     0.4119, tol(j)/tol(j-1)      0.991\n",
      "Maximum number of iterations reached, tolerance: 0.4119\n",
      "Elapsed time 0.0025 seconds\n",
      "Begin Newton-Kantorovich iterations (for the 1 time)\n",
      "Iteration 1, tol     0.9393, tol(j)/tol(j-1)          1\n",
      "Iteration 2, tol       0.13, tol(j)/tol(j-1)     0.1384\n",
      "Iteration 3, tol    0.02133, tol(j)/tol(j-1)      0.164\n",
      "Iteration 4, tol  0.0006562, tol(j)/tol(j-1)    0.03077\n",
      "Iteration 5, tol  2.616e-07, tol(j)/tol(j-1)  0.0003986\n",
      "Iteration 6, tol  9.095e-13, tol(j)/tol(j-1)  3.477e-06\n",
      "N-K converged after 6 iterations, tolerance: 9.095e-13\n",
      "Elapsed time 0.0106 seconds\n",
      "Convergence achieved!\n",
      "Elapsed time: 0.0135 (seconds)\n"
     ]
    }
   ],
   "source": [
    "algorithm = 'poly'\n",
    "do_settings_solver = {\n",
    "    'sa_min': 10,\n",
    "    'sa_max': 20,  \n",
    "    'printfxp': 2\n",
    "}\n",
    "\n",
    "solver = solve_NFXP(**do_settings_solver)\n",
    "model = zurcher()\n",
    "\n",
    "if algorithm == 'sa':\n",
    "    ev = solver.sa(model.bellman)\n",
    "if algorithm == 'poly':\n",
    "    ev = solver.poly(model.bellman)\n",
    "else:\n",
    "    print('Algorithm must be \"sa\" or \"poly\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Now we have to estimate the model. In order to estimate the model, you should understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.read_busdata </li>\n",
    "<li> estimate_NFXP.estimate  </li>\n",
    "<li> estimate_NFXP.ll  </li>\n",
    "</il>\n",
    "\n",
    "You can see how they are called below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fill in the missing stuff in the function estimate_NFXP.ll, and estimate the model to check that your results are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structual estimation using busdata from Rust(1987)\n",
      "Beta        = 0.9999\n",
      "n           = 175\n",
      "Sample size = 8156\n",
      " \n",
      "\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.8673     1.2072 \n",
      "c              1.3408     0.3199 \n",
      " \n",
      "p(1)           0.1069     0.0034  \n",
      "p(2)           0.5154     0.0055  \n",
      "p(3)           0.3621     0.0053  \n",
      "p(4)           0.0143     0.0013  \n",
      "\n",
      "Log-likelihood -8605.96\n",
      "runtime (seconds) 0.8712\n",
      "The model converged: True\n"
     ]
    }
   ],
   "source": [
    "# Set up the model\n",
    "model = zurcher()\n",
    "\n",
    "# Set-up solver\n",
    "solver = solve_NFXP()\n",
    "\n",
    "# Read the data\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "# Estimate the model\n",
    "import time\n",
    "t0 = time.time()\n",
    "theta0 = [0,0]\n",
    "\n",
    "# args for nfxp estimate\n",
    "nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "t1 = time.time()\n",
    "time = t1-t0\n",
    "\n",
    "# Print the result\n",
    "print(f'Structual estimation using busdata from Rust(1987)')\n",
    "print(f'Beta        = {model.beta:.4f}')\n",
    "print(f'n           = {model.n}')\n",
    "print(f'Sample size = {samplesize}\\n \\n')\n",
    "\n",
    "print(f'Parameters     Estimates    s.e. ') \n",
    "print(f'{pnames[0]}             {theta_hat[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "print(f'{pnames[1]}              {theta_hat[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "print(f'{pnames[2]}(1)           {theta_hat[2]:.4f}     {np.sqrt(Avar[2,2]):.4f}  ')\n",
    "print(f'{pnames[2]}(2)           {theta_hat[3]:.4f}     {np.sqrt(Avar[3,3]):.4f}  ')\n",
    "print(f'{pnames[2]}(3)           {theta_hat[4]:.4f}     {np.sqrt(Avar[4,4]):.4f}  ')\n",
    "print(f'{pnames[2]}(4)           {theta_hat[5]:.4f}     {np.sqrt(Avar[5,5]):.4f}  \\n')\n",
    "\n",
    "\n",
    "print(f'Log-likelihood {-optim_res.fun*samplesize:.2f}') \n",
    "print(f'runtime (seconds) {time:.4f}')\n",
    "print(f'The model converged: {converged}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Try using line_profiler in python. This gives you a lot of information about the performance of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.986763 s\n",
      "File: /Users/fedor/Dropbox/RESEARCH/08.teaching/00.current_courses/Aalto 2025/shared/practical_tasks/full_code/4_zurcher/ex-post/estimate_NFXP.py\n",
      "Function: estimate at line 9\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     9                                           def estimate(model,solver,data,theta0=[0,0],twostep=0):\n",
      "    10                                               global ev\n",
      "    11         1      11000.0  11000.0      0.0      ev = np.zeros(1) \n",
      "    12                                               \n",
      "    13         1      10000.0  10000.0      0.0      samplesize = data.shape[0]\n",
      "    14                                               # STEP 1: Find p \n",
      "    15         1    1118000.0 1.12e+06      0.1      tabulate = data.dx1.value_counts()\n",
      "    16         1     438000.0 438000.0      0.0      p = [tabulate[i]/sum(tabulate) for i in range(tabulate.size-1)]\n",
      "    17                                           \n",
      "    18                                               # STEP 2: Estimate structual parameters\n",
      "    19         1       3000.0   3000.0      0.0      model.p = p # Use first step estimates as starting values for p\n",
      "    20                                               \n",
      "    21                                               # Estimate RC and C\n",
      "    22         1       1000.0   1000.0      0.0      pnames = ['RC','c']\n",
      "    23                                               \n",
      "    24         1  757521000.0 7.58e+08     76.8      res = optimize.minimize(ll,theta0,args = (model, solver, data, pnames), method = 'trust-ncg',jac = grad, hess = hes, tol=1e-8)\n",
      "    25         1      10000.0  10000.0      0.0      model=updatepar(model,pnames,res.x)\n",
      "    26                                               \n",
      "    27                                               # Estimate RC, c and p\n",
      "    28         1          0.0      0.0      0.0      if twostep == 0:\n",
      "    29         1       1000.0   1000.0      0.0          pnames = ['RC','c','p']\n",
      "    30         1       2000.0   2000.0      0.0          theta0 = [model.RC, model.c] + model.p.tolist()\n",
      "    31         1  215289000.0 2.15e+08     21.8          res = optimize.minimize(ll,theta0, args = (model,solver,data, pnames), method = 'trust-ncg',jac = grad, hess = hes, tol = 1e-8)\n",
      "    32                                           \n",
      "    33         1      37000.0  37000.0      0.0          model=updatepar(model,pnames,res.x)\n",
      "    34                                           \n",
      "    35                                               # Converged\n",
      "    36         1       4000.0   4000.0      0.0      converged   =   (res.status == 2 or res.status ==0)\n",
      "    37                                           \n",
      "    38                                               # Compute Variance-Covaiance matrix\n",
      "    39         1   10976000.0  1.1e+07      1.1      h = hes(res.x, model, solver,data, pnames)\n",
      "    40         1    1338000.0 1.34e+06      0.1      Avar = np.linalg.inv(h*samplesize)\n",
      "    41                                           \n",
      "    42         1       3000.0   3000.0      0.0      theta_hat = res.x\n",
      "    43                                               \n",
      "    44         1       1000.0   1000.0      0.0      return model, res, pnames, theta_hat, Avar, converged\n",
      "\n",
      "Total time: 0.921497 s\n",
      "File: /Users/fedor/Dropbox/RESEARCH/08.teaching/00.current_courses/Aalto 2025/shared/practical_tasks/full_code/4_zurcher/ex-post/estimate_NFXP.py\n",
      "Function: ll at line 46\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    46                                           def ll(theta, model, solver,data, pnames, out=1): # out=1 solve optimization\n",
      "    47                                               global ev\n",
      "    48                                               \n",
      "    49                                               #Unpack\n",
      "    50        96    7942000.0  82729.2      0.9      x = np.array(data.x)\n",
      "    51        96    6938000.0  72270.8      0.8      d = np.array(data.d)\n",
      "    52        96    6078000.0  63312.5      0.7      dx1 = np.array(data.dx1)\n",
      "    53                                               \n",
      "    54                                               # Update values\n",
      "    55        96     902000.0   9395.8      0.1      model=updatepar(model,pnames,theta)\n",
      "    56        96     230000.0   2395.8      0.0      model.p = np.abs(model.p)    # helps BHHH which is run as unconstrained optimization\n",
      "    57        96   41870000.0 436145.8      4.5      model.create_grid()\n",
      "    58        96      59000.0    614.6      0.0      ev0 = ev\n",
      "    59                                           \n",
      "    60                                               # Solve the model\n",
      "    61        96  847879000.0 8.83e+06     92.0      ev, pk, dev = solver.poly(model.bellman, V0=ev0 ,beta=model.beta, output=3)\n",
      "    62                                           \n",
      "    63                                               # Evaluate likelihood function\n",
      "    64        96     878000.0   9145.8      0.1      lik_pr = pk[x]    \n",
      "    65        96    4899000.0  51031.2      0.5      log_lik = np.log(lik_pr+(1-2*lik_pr)*d)   \n",
      "    66                                           \n",
      "    67                                               # add on log like for mileage process\n",
      "    68        96      89000.0    927.1      0.0      if theta.size>2:\n",
      "    69        27     591000.0  21888.9      0.1          p = np.append(model.p,1-np.sum(model.p))\n",
      "    70        27      90000.0   3333.3      0.0          if any(p<=0):\n",
      "    71         2      25000.0  12500.0      0.0              log_lik -= 100000*p[dx1]\n",
      "    72                                                   else:\n",
      "    73        25    1087000.0  43480.0      0.1              log_lik += np.log(p[dx1])\n",
      "    74                                                   \n",
      "    75                                               else:\n",
      "    76        69      38000.0    550.7      0.0          p = np.nan\n",
      "    77                                           \n",
      "    78                                           \n",
      "    79        96      54000.0    562.5      0.0      if out == 1:\n",
      "    80                                                   # Objective function (negative mean log likleihood)\n",
      "    81        61    1789000.0  29327.9      0.2          return np.mean(-log_lik)\n",
      "    82                                           \n",
      "    83        35      59000.0   1685.7      0.0      return model,lik_pr, pk, ev, dev, d,x,dx1"
     ]
    }
   ],
   "source": [
    "%lprun -f estimate.ll  -f estimate.estimate estimate.estimate(model, solver,data,theta0=theta0, twostep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.016087 s\n",
      "File: /Users/fedor/Dropbox/RESEARCH/08.teaching/00.current_courses/Aalto 2025/shared/practical_tasks/full_code/4_zurcher/ex-post/Solve_NFXP.py\n",
      "Function: solve_NFXP.poly at line 30\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    30                                               def poly(self,bellman, V0=np.zeros(1), beta= 0.0, output=1):\n",
      "    31                                           \n",
      "    32         1       6000.0   6000.0      0.0          t0poly = time.time()  # set the starting time\n",
      "    33                                           \n",
      "    34         6       2000.0    333.3      0.0          for k in range(self.max_fxpiter):\n",
      "    35                                           \n",
      "    36                                                       # 1. CONTRACTION ITERATIONS (S-A)\n",
      "    37         5       8000.0   1600.0      0.0              if self.printfxp>0:\n",
      "    38                                                           print(f'Begin contraction iterations (for the {k+1} time)')\n",
      "    39         5    2362000.0 472400.0     14.7              V0,iter_sa= self.sa(bellman,V0,beta)\n",
      "    40                                           \n",
      "    41                                                       # 2. NEWTON-KANTOROVICH ITERATIONS\n",
      "    42         5       2000.0    400.0      0.0              if self.printfxp>0:\n",
      "    43                                                           print(f'Begin Newton-Kantorovich iterations (for the {k+1} time)')\n",
      "    44         5   13699000.0 2.74e+06     85.2              V0,pk,dV, iter_nk = self.nk(bellman,V0)\n",
      "    45                                           \n",
      "    46                                           \n",
      "    47         5       2000.0    400.0      0.0              t1poly = time.time()\n",
      "    48         5       2000.0    400.0      0.0              if iter_nk.converged=='true':\n",
      "    49         5       3000.0    600.0      0.0                  if self.printfxp>0:\n",
      "    50                                                               print(f'Convergence achieved!')\n",
      "    51                                                               print(f'Elapsed time: {(t1poly-t0poly):.4f} (seconds)')\n",
      "    52                                                               break \n",
      "    53                                                       else:\n",
      "    54                                                           if k >= self.max_fxpiter:\n",
      "    55                                                               print(f'No convergence! Maximum number of iterations exceeded without convergence!')\n",
      "    56                                                               break\n",
      "    57         1          0.0      0.0      0.0          V = V0\n",
      "    58         1          0.0      0.0      0.0          if output==1:            \n",
      "    59         1       1000.0   1000.0      0.0              return V\n",
      "    60                                                   if output==2:            \n",
      "    61                                                       return V, pk\n",
      "    62                                                   if output==3:            \n",
      "    63                                                       return V, pk, dV\n",
      "    64                                                   if output==5:            \n",
      "    65                                                       return V, pk, dV, iter_sa, iter_nk\n",
      "    66                                                   else:\n",
      "    67                                                       print('solve_NFXP.poly: output must be 1,2,3 or 5')\n",
      "\n",
      "Total time: 0.013627 s\n",
      "File: /Users/fedor/Dropbox/RESEARCH/08.teaching/00.current_courses/Aalto 2025/shared/practical_tasks/full_code/4_zurcher/ex-post/Solve_NFXP.py\n",
      "Function: solve_NFXP.nk at line 106\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   106                                               def nk(self,bellman, V0):\n",
      "   107         5      37000.0   7400.0      0.3          class iteration: pass\n",
      "   108         5       7000.0   1400.0      0.1          t0 = time.time()\n",
      "   109         5      14000.0   2800.0      0.1          iteration.tol =  np.nan+np.zeros((self.pi_max))\n",
      "   110         5       6000.0   1200.0      0.0          iteration.rtol = np.nan+np.zeros((self.pi_max))\n",
      "   111         5       9000.0   1800.0      0.1          iteration.converged = 'false'\n",
      "   112                                           \n",
      "   113         5       5000.0   1000.0      0.0          m = V0.size\n",
      "   114                                           \n",
      "   115         8       7000.0    875.0      0.1          for i in range(self.pi_max):\n",
      "   116                                           \n",
      "   117                                                       # Do N-K step\n",
      "   118         8    3379000.0 422375.0     24.8              V1, pk, dV = bellman(V0,output=3)\n",
      "   119         8    1119000.0 139875.0      8.2              F = np.eye(m)-dV\n",
      "   120         8    8576000.0 1.07e+06     62.9              V = V0 - np.linalg.inv(F) @ (V0 - V1) \n",
      "   121                                                       \n",
      "   122                                                       # do additional SA iteration for stability and accurate measure of error bound\n",
      "   123         8     216000.0  27000.0      1.6              V0 = bellman(V,output=1)\n",
      "   124                                           \n",
      "   125                                                       # Tolerance\n",
      "   126         8     102000.0  12750.0      0.7              iteration.tol[i]=max(abs(V-V0))\n",
      "   127         8      13000.0   1625.0      0.1              iteration.rtol[i] = iteration.tol[i]/(iteration.tol[max(i-1,0)] + 1.0e-15)      \n",
      "   128                                           \n",
      "   129                                                       #Adjust \n",
      "   130         8      79000.0   9875.0      0.6              adj  = np.ceil(np.log10(abs(max(V0))))\n",
      "   131         8       6000.0    750.0      0.0              ltol = self.pi_tol*10**adj  # Adjust final tolerance\n",
      "   132                                           \n",
      "   133         8       6000.0    750.0      0.0              if iteration.tol[i] < ltol:\n",
      "   134                                                           #Convergence achieved\n",
      "   135         5      14000.0   2800.0      0.1                  iteration.message = \"N-K converged after {} iterations, tolerance: {:.4g}\".format(i+1,iteration.tol[i])\n",
      "   136         5       1000.0    200.0      0.0                  iteration.converged = 'true'\n",
      "   137         5       1000.0    200.0      0.0                  break\n",
      "   138                                                   \n",
      "   139         5       2000.0    400.0      0.0          iteration.n = i+1\n",
      "   140         5       4000.0    800.0      0.0          iteration.tol = iteration.tol[0:i+1]\n",
      "   141         5       4000.0    800.0      0.0          iteration.rtol = iteration.rtol[0:i+1]\n",
      "   142         5       3000.0    600.0      0.0          t1 = time.time()\n",
      "   143         5       3000.0    600.0      0.0          iteration.time = t1-t0 \n",
      "   144                                           \n",
      "   145         5       7000.0   1400.0      0.1          self.print_output(iteration)\n",
      "   146                                           \n",
      "   147         5       7000.0   1400.0      0.1          return V, pk, dV, iteration"
     ]
    }
   ],
   "source": [
    "%lprun -f solve_NFXP.nk -f solve_NFXP.poly solve_NFXP.poly(solver,model.bellman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Now try changing the optimizer options, and turn the use of the non-numerical Hessian off . What happens?\n",
    "\n",
    "b) Now also try it with the analytical gradient off, what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHHH:\n",
      "Time is 0.8105 seconds. The model converges: True\n",
      "Time is 0.8942 seconds. The model converges: True\n",
      "Time is 0.7977 seconds. The model converges: True\n",
      "Time is 0.8472 seconds. The model converges: True\n",
      "Time is 0.8382 seconds. The model converges: True\n",
      "Time is 0.7887 seconds. The model converges: True\n",
      "Time is 0.7889 seconds. The model converges: True\n",
      "Time is 0.7745 seconds. The model converges: True\n",
      "819 ms ± 40.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Hessian is off:\n",
      "Time is 2.6866 seconds. The model converges: True\n",
      "Time is 2.7291 seconds. The model converges: True\n",
      "Time is 2.5218 seconds. The model converges: True\n",
      "Time is 2.5294 seconds. The model converges: True\n",
      "Time is 2.6384 seconds. The model converges: True\n",
      "Time is 2.5949 seconds. The model converges: True\n",
      "Time is 2.5132 seconds. The model converges: True\n",
      "Time is 2.9200 seconds. The model converges: True\n",
      "2.64 s ± 137 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Hessian and gradient are off:\n",
      "Time is 2.0255 seconds. The model converges: True\n",
      "Time is 1.8655 seconds. The model converges: True\n",
      "Time is 1.8223 seconds. The model converges: True\n",
      "Time is 1.7137 seconds. The model converges: True\n",
      "Time is 1.8835 seconds. The model converges: True\n",
      "Time is 2.6253 seconds. The model converges: True\n",
      "Time is 1.7092 seconds. The model converges: True\n",
      "Time is 1.4601 seconds. The model converges: True\n",
      "1.87 s ± 336 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import alternative_specifications_ex7 as a_s_ex7\n",
    "\n",
    "model = zurcher()\n",
    "solver = solve_NFXP()\n",
    "\n",
    "#Ordinaty\n",
    "print('BHHH:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=0)\n",
    "\n",
    "\n",
    "# Hessian off\n",
    "print('')\n",
    "print('Hessian is off:')\n",
    "%timeit nfxp_result = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=1)\n",
    "\n",
    "\n",
    "#Hessian and gradient ofF \n",
    "print('')\n",
    "print('Hessian and gradient are off:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Try estimate the model for different values of $\\beta$. \n",
    "\n",
    "(a) Why can we not estimate $\\beta$?\n",
    "\n",
    "(b) When estimating with different $\\beta$, do the changes in the estimates of c and/or RC make intuitively sense?\n",
    "\n",
    "(c) Can you think of some data/variation, which could allow us to identify $\\beta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta     RC     C       log_lik\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fedor/Dropbox/RESEARCH/08.teaching/00.current_courses/Aalto 2025/shared/practical_tasks/full_code/4_zurcher/ex-post/Solve_NFXP.py:91: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  iteration.rtol[i] = iteration.tol[i]/iteration.tol[max(i-1,0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000 7.3884 18.4389 [-8612.02184954] \n",
      "0.6666 7.4518 12.6589 [-8611.72814884] \n",
      "0.8333 7.6458 6.9304 [-8610.88770501] \n",
      "0.9999 9.8673 1.3408 [-8605.96286488] \n"
     ]
    }
   ],
   "source": [
    "# VARY BETA: \n",
    "Nbeta = 4\n",
    "beta = np.linspace(0.5,0.9999,Nbeta)\n",
    "log_lik = np.nan + np.zeros((Nbeta,1))\n",
    "theta_hats =  np.nan + np.zeros((Nbeta,2))\n",
    "\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "print(f'beta     RC     C       log_lik')\n",
    "for i in range(Nbeta):\n",
    "    \n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'beta': beta[i]\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    theta_hats[i,0] = theta_hat[0]\n",
    "    theta_hats[i,1] = theta_hat[1]\n",
    "    log_lik[i]=-optim_res.fun*samplesize\n",
    "    print(f'{beta[i]:.4f} {theta_hats[i,0]:.4f} {theta_hats[i,1]:.4f} {log_lik[i]} ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. We use the latest EV guess to start the solve-procedure even though we change $\\theta$ from one likelihood iteration to another. Why do you think we do that? \n",
    "(a) What if we started over with EV=0 each iteration? Try that and see what happens with the parameters and the numerical performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same EV\n",
      "987 ms ± 93.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "EV=0\n",
      "1.22 s ± 36.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "                 Same EV       EV=0\n",
      "RC               9.8673       9.8673\n",
      "c                1.3408       1.3408\n"
     ]
    }
   ],
   "source": [
    "import alternative_specifications_ex9 as a_s_ex9 \n",
    "\n",
    "# Ordinary\n",
    "print('Same EV')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,0)\n",
    "nfxp_results_ord, theta_hat_ord = a_s_ex9.estimate(model, solver,data,0)\n",
    "\n",
    "\n",
    "# Change EV=0 in each iteration\n",
    "print('EV=0')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,1)\n",
    "nfxp_results_diff, theta_hat_diff = a_s_ex9.estimate(model, solver,data,1)\n",
    "\n",
    "print('')\n",
    "print(f'                 Same EV       EV=0')\n",
    "print(f'{pnames[0]}               {theta_hat_ord[0]:.4f}       {theta_hat_diff[0]:.4f}')\n",
    "print(f'{pnames[1]}                {theta_hat_ord[1]:.4f}       {theta_hat_diff[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Try setting the maximum number of miles (odometer reading) to 900. Now the absorbing state is much higher. \n",
    "\n",
    "(a) If we adjust the number of grid points as well, so that we have a comparable model (multiply the number of grids by 2), do we get a better fit? \n",
    "\n",
    "(b) Try to lower the number of grid points to 175 again. How do the parameters change? Are the changes intuitive? \n",
    "\n",
    "(c) What if you change the max to 225 and half the number of grids (hint: what goes wrong?)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adjusting Grid-points\n",
    "def adjust_grid_point(maks, n):\n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'max': maks,\n",
    "    'n': n\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "        \n",
    "    # Read the data\n",
    "    data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "    samplesize = data.shape[0]\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    nfxp_model, result, pnames, theta, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    print(f'Parameters     Estimates    s.e. ') \n",
    "    print(f'{pnames[0]}             {theta[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "    print(f'{pnames[1]}              {theta[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "    print(f'Log-likelihood now {-result.fun*samplesize:.4f}\\n \\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.8673     1.2072 \n",
      "c              1.3408     0.3199 \n",
      " \n",
      "Log-likelihood now -8605.9629\n",
      " \n",
      "\n",
      "Question (a)\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.8728     1.2288 \n",
      "c              1.3401     0.3288 \n",
      " \n",
      "Log-likelihood now -8605.9826\n",
      " \n",
      "\n",
      "Question (b)\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.8886     1.2326 \n",
      "c              1.7871     0.4404 \n",
      " \n",
      "Log-likelihood now -7411.9098\n",
      " \n",
      "\n",
      "Question (c)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 86 is out of bounds for axis 0 with size 86",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# c) max =225, n = 175/2\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion (c)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m adjust_grid_point(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m450\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m),\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m175\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m, in \u001b[0;36madjust_grid_point\u001b[0;34m(maks, n)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Estimate the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m theta0 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m nfxp_model, result, pnames, theta, Avar, converged\u001b[38;5;241m=\u001b[39mestimate\u001b[38;5;241m.\u001b[39mestimate(model, solver,data,theta0\u001b[38;5;241m=\u001b[39mtheta0, twostep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameters     Estimates    s.e. \u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpnames[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m             \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtheta[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m     \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msqrt(Avar[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Dropbox/RESEARCH/08.teaching/00.current_courses/Aalto 2025/shared/practical_tasks/full_code/4_zurcher/ex-post/estimate_NFXP.py:24\u001b[0m, in \u001b[0;36mestimate\u001b[0;34m(model, solver, data, theta0, twostep)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Estimate RC and C\u001b[39;00m\n\u001b[1;32m     22\u001b[0m pnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRC\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m res \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mminimize(ll,theta0,args \u001b[38;5;241m=\u001b[39m (model, solver, data, pnames), method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-ncg\u001b[39m\u001b[38;5;124m'\u001b[39m,jac \u001b[38;5;241m=\u001b[39m grad, hess \u001b[38;5;241m=\u001b[39m hes, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m=\u001b[39mupdatepar(model,pnames,res\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Estimate RC, c and p\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/scipy/optimize/_minimize.py:732\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    729\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_dogleg(fun, x0, args, jac, hess,\n\u001b[1;32m    730\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-ncg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 732\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trust_ncg(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    733\u001b[0m                               callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-krylov\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trust_krylov(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    736\u001b[0m                                  callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/scipy/optimize/_trustregion_ncg.py:37\u001b[0m, in \u001b[0;36m_minimize_trust_ncg\u001b[0;34m(fun, x0, args, jac, hess, hessp, **trust_region_options)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m hessp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither the Hessian or the Hessian-vector product \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     36\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis required for Newton-CG trust-region minimization\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_trust_region(fun, x0, args\u001b[38;5;241m=\u001b[39margs, jac\u001b[38;5;241m=\u001b[39mjac, hess\u001b[38;5;241m=\u001b[39mhess,\n\u001b[1;32m     38\u001b[0m                               hessp\u001b[38;5;241m=\u001b[39mhessp, subproblem\u001b[38;5;241m=\u001b[39mCGSteihaugSubproblem,\n\u001b[1;32m     39\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrust_region_options)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/scipy/optimize/_trustregion.py:175\u001b[0m, in \u001b[0;36m_minimize_trust_region\u001b[0;34m(fun, x0, args, jac, hess, hessp, subproblem, initial_trust_radius, max_trust_radius, eta, gtol, maxiter, disp, return_all, callback, inexact, **unknown_options)\u001b[0m\n\u001b[1;32m    171\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x0)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# A ScalarFunction representing the problem. This caches calls to fun, jac,\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# hess.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m sf \u001b[38;5;241m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[38;5;241m=\u001b[39mjac, hess\u001b[38;5;241m=\u001b[39mhess, args\u001b[38;5;241m=\u001b[39margs)\n\u001b[1;32m    176\u001b[0m fun \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m    177\u001b[0m jac \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/scipy/optimize/_optimize.py:288\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    284\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m sf \u001b[38;5;241m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m    289\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:166\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/Dropbox/RESEARCH/08.teaching/00.current_courses/Aalto 2025/shared/practical_tasks/full_code/4_zurcher/ex-post/estimate_NFXP.py:64\u001b[0m, in \u001b[0;36mll\u001b[0;34m(theta, model, solver, data, pnames, out)\u001b[0m\n\u001b[1;32m     61\u001b[0m ev, pk, dev \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mpoly(model\u001b[38;5;241m.\u001b[39mbellman, V0\u001b[38;5;241m=\u001b[39mev0 ,beta\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbeta, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Evaluate likelihood function\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m lik_pr \u001b[38;5;241m=\u001b[39m pk[x]    \n\u001b[1;32m     65\u001b[0m log_lik \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(lik_pr\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mlik_pr)\u001b[38;5;241m*\u001b[39md)   \n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# add on log like for mileage process\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 86 is out of bounds for axis 0 with size 86"
     ]
    }
   ],
   "source": [
    "# Baseline max = 450, n = 175\n",
    "print(f'Baseline')\n",
    "adjust_grid_point(450,175);\n",
    "\n",
    "# a)  max = 900, n = 175*2\n",
    "print(f'Question (a)')\n",
    "adjust_grid_point(450*2,175*2)\n",
    "\n",
    "# b) max = 600, n = 175\n",
    "print(f'Question (b)')\n",
    "adjust_grid_point(600,175)\n",
    "\n",
    "# c) max =225, n = 175/2\n",
    "print(f'Question (c)')\n",
    "adjust_grid_point(int(450/2),int(175/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
